{
 "metadata": {
  "name": "",
  "signature": "sha256:80bf8f0679941dfa545746171b77a510d454c4c9b6d7dc4a7a902f7990bebb44"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB, BernoulliNB  # Naive Bayes model classes\n",
      "from sklearn.feature_extraction.text import CountVectorizer  # convert text into feature vectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "from sklearn.cross_validation import train_test_split  # split the data you have into training and test sets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# blah = 'on peoplecom \\xe2 \\x80'\n",
      "# re.sub(r'([^\\w|\\s])+','',blah)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import re\n",
      "from nltk.tokenize import wordpunct_tokenize  # for tokenizing our text\n",
      "import string  # helps with removing punctuation\n",
      "\n",
      "buzz_word_bag_list = []\n",
      "with open('text_dict.csv', 'rb') as r: \n",
      "    reader = csv.reader(r)\n",
      "    for doc in reader:\n",
      "        cleaned = doc[0].replace('-', ' ')\n",
      "        cleaned = re.sub(r'([^\\w|\\s])+','',cleaned)\n",
      "        cleaned = re.sub(r'\\d','',cleaned)\n",
      "        for c in string.punctuation:  # strip punctuation marks.\n",
      "            cleaned = cleaned.replace(c, '')\n",
      "        buzz_word_bag_list.append(wordpunct_tokenize(cleaned.lower()))\n",
      "\n",
      "buzz_word_list = []\n",
      "for tokens in buzz_word_bag_list:\n",
      "    buzz_word_list.extend(tokens)\n",
      "      \n",
      "corpus = []\n",
      "for text in buzz_word_list:\n",
      "    uni_text = ''.join([i if ord(i) < 128 else '' for i in text])\n",
      "    corpus.append((uni_text,1))\n",
      "print len(corpus) \n",
      "nyt_word_bag_list = [] \n",
      "with open('nytimesdata.csv', 'rb') as r: \n",
      "    reader = csv.reader(r)\n",
      "    for doc in reader:\n",
      "        cleaned = doc[0].replace('-', ' ')\n",
      "        cleaned = re.sub(r'([^\\w|\\s])+','',cleaned)\n",
      "        cleaned = re.sub(r'\\d','',cleaned)\n",
      "#         cleaned = str(doc).replace('-', ' ')  # make lowercase and split hyphenated words in two\n",
      "        for c in string.punctuation:  # strip punctuation marks.\n",
      "            cleaned = cleaned.replace(c, '')         \n",
      "        nyt_word_bag_list.append(wordpunct_tokenize(cleaned.lower()))\n",
      "\n",
      "nyt_word_list = []\n",
      "for tokens in nyt_word_bag_list:    \n",
      "    nyt_word_list.extend(tokens)  \n",
      "    \n",
      "for text in nyt_word_list:\n",
      "    uni_text = ''.join([i if ord(i) < 128 else '' for i in text])\n",
      "    corpus.append((uni_text,0))\n",
      "    \n",
      "print len(corpus)        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "69609\n",
        "100494"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def count_most_freq(bag_in):\n",
      "    from collections import Counter \n",
      "    token_list = []\n",
      "\n",
      "    print 'number of tokens:', len(bag_in)\n",
      "    print 'number of unique tokens:', len(set(bag_in))\n",
      "\n",
      "    df = Counter()  # initialize this dict-like thing.\n",
      "\n",
      "    for doc in bag_in:\n",
      "        # count up the times words appear in INDIVIDUAL documents (not the total across all documents)\n",
      "#         for word in doc:  # edit this, obviously\n",
      "            # add one to the right key in df\n",
      "            df[doc] += 1\n",
      "\n",
      "    for token in df:\n",
      "#         # normalize the counts by the number of documents (are you getting zeros? Think datatypes.)\n",
      "        df[token] = 1.0*df[token]/len(bag_in)\n",
      "\n",
      "\n",
      "    # this last line prints the 20 highest-scoring words and their scores\n",
      "    print df.most_common(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "count_most_freq(buzz_word_list)\n",
      "count_most_freq(nyt_word_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of tokens: 69609\n",
        "number of unique tokens: 9495\n",
        "[('the', 0.037294028071082765), ('to', 0.023560171816862763), ('a', 0.021362180177850566), ('you', 0.019710094958985187), ('of', 0.01966699708371044), ('in', 0.015601430849459122), ('is', 0.013231047709347929), ('this', 0.011981209326380209), ('that', 0.01182318378370613), ('and', 0.01068827306813774), ('your', 0.008921260181873034), ('on', 0.00843281759542588), ('for', 0.007728885632604979), ('are', 0.00768578775733023), ('things', 0.006838196210260167), ('will', 0.006694536626011004), ('about', 0.006464681291212343), ('who', 0.005573991868867531), ('people', 0.00550216207674295), ('with', 0.00534413653406887)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "number of tokens: 30885\n",
        "number of unique tokens: 6940\n",
        "[('to', 0.03286384976525822), ('in', 0.03108305002428363), ('for', 0.01677189574226971), ('of', 0.015800550429010848), ('us', 0.012174194592844422), ('on', 0.011429496519345961), ('at', 0.007252711672332848), ('with', 0.005828071879553181), ('after', 0.005342399222923749), ('new', 0.005342399222923749), ('says', 0.005115751983163348), ('china', 0.00479197021207706), ('over', 0.00479197021207706), ('man', 0.004759592034968431), ('california', 0.004306297555447629), ('as', 0.0039825157843613405), ('police', 0.0039825157843613405), ('from', 0.0039177594301440825), ('by', 0.0033349522421887647), ('obama', 0.003140683179536992)]\n"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# corpus = pickle.load(open('corpus.p', 'rb'))\n",
      "# convert features\n",
      "text, Y = zip(*corpus)\n",
      "\n",
      "vectorizer = CountVectorizer()\n",
      "# vectorizer = CountVectorizer(ngram_range=(1,2))\n",
      "# vectorizer = CountVectorizer(stop_words='english')\n",
      "# vectorizer = CountVectorizer(ngram_range=(1,3),stop_words='english')\n",
      "X = vectorizer.fit_transform(text)\n",
      "# print list(enumerate(vectorizer.get_feature_names()))\n",
      "xtrain, xtest, ytrain, ytest = train_test_split(X, Y)\n",
      "\n",
      "best_MNB_alpha = 1\n",
      "best_BNB_alpha = 1\n",
      "best_MNB_score = 0\n",
      "best_BNB_score = 0\n",
      "for alph in range(5,6):\n",
      "    \n",
      "    MNB_score = 0\n",
      "    BNB_score = 0\n",
      "    clf_MNB = MultinomialNB(alpha=alph).fit(xtrain, ytrain)\n",
      "    print alph\n",
      "    print clf_MNB.score(xtrain, ytrain) \n",
      "    print clf_MNB.score(xtest, ytest)\n",
      "    print (clf_MNB.score(xtrain, ytrain) +clf_MNB.score(xtest, ytest))/2    \n",
      "#     average_count = 100\n",
      "    \n",
      "#     for i in range(average_count):\n",
      "#         xtrain, xtest, ytrain, ytest = train_test_split(X, Y)\n",
      "\n",
      "#         # Create our classifier\n",
      "#         clf_MNB = MultinomialNB(alpha=alph).fit(xtrain, ytrain)\n",
      "#         print clf_MNB.score(xtrain, ytrain)\n",
      "#         MNB_score += (100 * clf_MNB.score(xtest, ytest))\n",
      "#         print clf_MNB.score(xtest, ytest)\n",
      "#         clf_BNB = BernoulliNB(alpha=alph).fit(xtrain, ytrain)\n",
      "#         BNB_score += (100 * clf_BNB.score(xtest, ytest))\n",
      "    \n",
      "#     cur_MNB_score = MNB_score/average_count\n",
      "#     cur_BNB_score = BNB_score/average_count\n",
      "    \n",
      "#     if cur_MNB_score > best_MNB_score:\n",
      "#         best_MNB_score = cur_MNB_score\n",
      "#         best_MNB_alpha = alph\n",
      "        \n",
      "#     if cur_BNB_score > best_BNB_score:\n",
      "#         best_BNB_score = cur_BNB_score\n",
      "#         best_BNB_alpha = alph\n",
      "    \n",
      "# print \"Best MNB Accuracy: %0.2f%% for alpha = %d\" % (best_MNB_score, best_MNB_alpha)\n",
      "# print \"Best BNB Accuracy: %0.2f%% for alpha = %d\" % (best_BNB_score, best_BNB_alpha)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5\n",
        "0.764946265092\n",
        "0.750557236109\n",
        "0.757751750601\n"
       ]
      }
     ],
     "prompt_number": 278
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean_headlines(headlines_in):\n",
      "    head_list_multi = []\n",
      "    for doc in headlines_in:\n",
      "        cleaned = doc.replace('-', ' ') \n",
      "        cleaned = re.sub(r'([^\\w|\\s])+','',cleaned)\n",
      "        cleaned = re.sub(r'\\d','',cleaned)\n",
      "        for c in string.punctuation:  # strip punctuation marks.\n",
      "            cleaned = cleaned.replace(c, '')\n",
      "        head_list_multi.append(wordpunct_tokenize(cleaned.lower()))\n",
      "    \n",
      "    head_list = []\n",
      "    for tokens in head_list_multi:    \n",
      "        head_list.append(' '.join(tokens))  \n",
      "    return head_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 274
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# yahoo = [\"Netanyahu says Israel will hit Hamas hard\", \"Man killed in front of son in California freeway shooting: report\", \"Senate panel doubles money for Israel's Iron Dome\", \"Church lawyer details cover-up claims on sex abuse\", \"Billionaire's breakup plan would chop California into six states\", \"Four Things That Can Send Your Resume to the Trash\", \"Why Hamas Rejected the Israel-Approved Egyptian Ceasefire\", \"Man kills wife, granddaughter; gets life in prison\", \"China tells U.S. to stay out of South China Seas dispute\", \"White House contests subpoena of top Obama political aide\",\"Why Americans Refrigerate Eggs and Europeans Don't\"]\n",
      "# NYT = [\"Skeptic of Climate Change Finds Himself a Target of Suspicion \",\"Obama Presses Congress for Long-Term Transportation Bill \",\"Well: A Spoonful of Medicine May Put Children at Risk \",\"As Border Tensions Rise, Ukraine and Russia Draw Nearer to Direct Conflict \",\"ArtsBeat: MoMA Names New Architecture and Design Curator \",\"Chinese Hackers Extend Reach to Smaller U.S. Agencies, Officials Say \",\"Budget Office Revises Estimate of Federal Spending on Health Care \",\"My Life as an Undocumented Immigrant \",\"Seeding the Field: A Qatari Soccer Program Looking to Rise Buys a Foothold in Europe \"]\n",
      "# Fox = ['Government watchdogs slam Obama agencies for stonewalling probes', 'scale is staggering huge russian data breach could worsen experts say', 'REICH RAKES IN DOUGHEx-Clinton official lectures on greed, but makes big', 'TODD STARNES Soldier Career cut short over Hannity, Chick-fil-A','What message does US response in Iraq send to Russia, world?','Judge Napolitano provides insight into Bergdahl Army probe', 'Double standard over civilian deaths in the Mideast?', 'Airports on high alert for fliers with Ebola symptoms', \"FDA considers nutrition label overhaul on added sugar\",'Post-it payback for prankster police officer'] \n",
      "NYT = ['Clashes Erupt in Liberia Over Mass Ebola Quarantine', \"Obama Appalled by Beheading, Will Continue Airstrikes\", 'Letter From India: Narendra Modi to Replace Indias Planning Commission', 'Experimental Drug Used for Ebola-Related Virus Shows Promise', 'Idled Russian Aid Convoy Gets Back on Road to Ukraine', 'Fed Dissenters Increasingly Vocal About Inflation Fears', 'Tension Easing in Ferguson, Focus Turns to Inquiry', 'Costly Corporate Gadflies', 'Fed Dissenters Increasingly Vocal About Inflation Fears', 'Metropolitan Opera Clears Last Major Hurdle in Labor Talks' ]\n",
      "Fox = ['HE WAS BEATEN VERY SEVERELY Source claims attack on Ferguson cop', 'ORPHANS IN LIMBO Congo adoption freeze forces US families to wait', 'EXTRACT THIS CANCER US ramps up airstrikes in Iraq, weighs more troops', 'TODD STARNES Student punished for less you after sneeze', 'Phares: Beheading shows ISIS knew clash with US was coming', 'Missouri lieutenant governor criticizes Governor Jay Nixon', '140 rockets fired from Gaza since truce collapsed', 'Tom DeLay on criminalization of politics by left in Texas', 'Brown Family attorney speaks out about case', 'fast-moving storms force dramatic rescues']\n",
      "ABC_Oz = ['Doctors reject co-payment plan','Second miracle for family','TV turned up after screams', 'Palmer no-show irks committee', 'Inquiry into FIFO suicides', 'Pollies copping a bucketing', 'World leaders condemn barbaric beheading of captured journalist','Rubbish collections stop after truck fleet grounded', 'Russia shuts McDonalds outlets amid Ukraine fighting','Banker charged with stealing $35k from MH370 victims']\n",
      "Onion = ['Man Wearing Low-Cut Swimsuit As Though Public Pool A Sun-Kissed Sardinian Cove', 'Study Finds 79% Of Statistics Now Sobering', 'Chinese Journalists Bemoan Decline Of Traditional State-Run Newspapers, Rise Of State-Run New Media', 'Area Facebook User Incredibly Stupid', 'Sometimes Unfortunate Things Happen In The Heat Of A 400-Year-Old Legacy Of Racism', 'I\u2019m Always Open To Feedback That I Can Get Defensive About And Ultimately Ignore', 'More Women Getting Hand Surgery To Look Good In Ring Selfies', 'Geneticists Debate Ethics Of Cloning Humans And Forcing Them To Fight To Death In Pit For Our Amusement', 'Teary-Eyed Wrestlers Bid Farewell To Friends Made At SummerSlam','Fourth-Grade Teacher Polishing Up Speech On This Not Being Third Grade Anymore' ]\n",
      "buzzfeed = ['21 Secrets Overly Competitive People Will Never Tell You', 'The Essential Ladies Guide To Gaining Confidence From Construction Workers', '22 Of Life\u2019s Most Annoying Situations Can Be Summed Up Perfectly With This GIF', 'I Thought This Was Just Another Basic ALS Ice Bucket Challenge Until I Saw Trey Songz Wearing Basketball Shorts In The Background', '17 Songs That Have The Power To Change Your Life', 'Unreal Photos Of Chicago Air Show Make Planes Look Like Little Toys', '13 Things That Cost As Much As Having A Kid', 'Emma Stone Will Make Her Broadway Debut In \"Cabaret\" This Fall','Which Plantain Dish Matches Your Personality?', 'Israel Is Barring Amnesty International And Human Rights Watch From Investigating The Gaza War' ]\n",
      "BBC = ['Obama: Foley video shocks the world', 'Israel PM vows further Gaza campaign', 'Attorney General arrives in Ferguson', 'Liberia troops enforce quarantine', 'UN begins huge aid drop in Iraq', 'Russia convoy at Ukraine customs', 'Guatemalan top general dies in crash', 'Iceland evacuates area near volcano', 'Russia shuts four Moscow McDonalds', 'Rain sparks deadly Japan landslides']\n",
      "ABC = ['James Foleys Parents Recall Sons Big Heart', 'Apparent\u2019 That James Foley Executioner Is British: Official', 'Makeup Artist Uses Chin as Canvas', 'James Foley Punished for Suspected Escape Plans, Fellow Hostage Says', 'Ferguson Cop Had Serious Facial Injury, Source Tells ABC News', 'Rick Perry\u2019s Mugshot vs. Official Governor\u2019s Portrait, Which Is Better?', 'Does a Cool Summer Signal Another Cold and Snowy Winter?', 'Indiana Police Investigate Possible Link in Moms\u2019 Disappearances', 'How Billy Crystal will Honor Robin Williams at the 2014 Emmys', 'Why Elise Mosca Left Bachelor in Paradise With Chris Bukowski' ]\n",
      "CNN = ['Cop: Just do what I tell you', 'U.S. steps up pressure despite threat', 'Bush takes plunge, challenges Clinton', 'Sit anywhere with this invisible chair', 'Cheetah cub and puppy make friends', 'Where are they now?', 'Billy Crystal to honor Williams at Emmys', 'Rat attack on NYC subway', 'Skateboarder beats, kicks park ranger', 'Dare you to watch this without laughing']\n",
      "WJ = ['Fed Debate on Rate Increase Heats Up', 'Obama Denounces Killing Of American Journalist', 'Some Insurgent Commanders Retreat to Syria', 'BofA, U.S. Reach $17 Billion Settlement', 'Ferguson and Americas Racial Fears', 'The Medical Innovation Threat', 'What the Taxi Wars Teach', 'Germans Learn Why Friends Spy on Friends', 'Stocks Rise, Shrug Off Fed Minutes','Ebola Quarantine Sparks Liberia Clashes']\n",
      "LA_times = ['Obama vows justice after militants kill U.S. journalist','Assembly approves measure to block suspended lawmakers pay', 'Supreme Court blocks ruling that would have allowed gay marriages in Virginia', 'Ebola threat: Liberia seals off slum, clashes erupt', 'Al Jazeera America rejects allegations in Al Gores lawsuit','L.A. to pay $5 million to family of Corvette driver killed by LAPD','Air Force grounds 82 fighter jets after cracks are found near cockpit','Gov. criticizes pension board decision allowing bigger retirement benefits','Michael Brown shooting hearing expected to last until mid-October', 'Suspect in Marine wifes slaying may have feared she was pregnant']\n",
      "NBC = ['James Foley Remembered as A Man of Incredible Bravery Man of Incredible Bravery: Why Foley Risked His Life to Report', 'U.S. Hits ISIS From Air Near Mosul Dam', 'Supreme Court Halts Gay Marriage in Virginia', 'Watching James Foley Video May Mean Charges in U.K.', 'Bob McDonnell Takes the Stand in His Own Defense', 'Billy Crystal to Honor Robin Williams at Emmys', 'State Department Wants 300 More Troops for Iraq','Journalists Targeted: Killing Is Latest in Bloody Trend', 'Nine Ice Bucket Challenges You Need to See','Obama: No Just God Would Stand For What They Did']\n",
      "Huff_post = ['NO PLACE FOR ISIS THIS CENTURY', ' Awesome DIY Crafts You Can Make With Your Kids', 'Jindal Blocked.. Begich Secret Weapon.. McConnell Warms Up.. More Tea Party Drama.. Mitt Shadowed', 'Cop Who Told Ferguson Protestors: I Will F**king Kill You, Suspended', 'RANKED: The 16 Best Towns To Live In', '40 Percent of American Workers Will Leave Paid Vacation Days Unused', 'Supreme Court Puts Hold On Same-Sex Marriages In Virginia', 'How These Righteous Religious Leaders in Ferguson Are Giving Us Hope', 'WTF Renaissance Art.. What Orgasms Really Look Like.. NYC Street Art Guide.. Who Is FKA Twigs?', 'What These Adults Got REALLY Wrong About Sex'  ]\n",
      "USA_today = ['Foley set out to record most important things', 'no end in sight to ebola outbreak official says', 'doctor no evidence of cancer for jim kelly', 'simple ways to boost your savings', 'obama says nation is heardbroken by foleys beheading','Supreme Court blocks same-sex marriages in Virginia', 'AG Holder arrives in Missouri amid uneasy peace in Ferguson','Carl icahn picks his latest target', 'Ex-Va. Gov. McDonnell takes stand in corruption trial','Tony Stewart will not race at Bristol Motor Speedway'  ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# NYT = ['Banned U.S. Sprinter Gay to Make Return in Lausanne']\n",
      "# yahoo = clean_headlines(yahoo)\n",
      "NYT = clean_headlines(NYT)\n",
      "Fox = clean_headlines(Fox)\n",
      "ABC_Oz = clean_headlines(ABC_Oz)\n",
      "Onion = clean_headlines(Onion)\n",
      "buzzfeed = clean_headlines(buzzfeed)\n",
      "BBC = clean_headlines(BBC)\n",
      "ABC = clean_headlines(ABC)\n",
      "CNN = clean_headlines(CNN)\n",
      "WJ = clean_headlines(WJ)\n",
      "LA_times = clean_headlines(LA_times)\n",
      "NBC = clean_headlines(NBC)\n",
      "Huff_post = clean_headlines(Huff_post)\n",
      "USA_today = clean_headlines(USA_today)\n",
      "\n",
      "\n",
      "print len(Fox)\n",
      "print len(NYT)\n",
      "print len(ABC_Oz)\n",
      "print len(Onion)\n",
      "print len(buzzfeed)\n",
      "print len(BBC)\n",
      "print len(ABC)\n",
      "print len(CNN)\n",
      "print len(WJ)\n",
      "print len(LA_times)\n",
      "print len(NBC)\n",
      "print len(Huff_post)\n",
      "print len(USA_today)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10\n",
        "10\n",
        "10\n",
        "10\n",
        "10\n",
        "10\n",
        "10\n",
        "10\n",
        "10\n",
        "10\n",
        "10\n",
        "10\n",
        "10\n"
       ]
      }
     ],
     "prompt_number": 275
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "#1 buzz, 0 NYT\n",
      "clf_MNB = MultinomialNB(alpha=1).fit(X, Y)\n",
      "\n",
      "newVec = CountVectorizer(vocabulary=vectorizer.vocabulary_)\n",
      "\n",
      "# yahooXnew = newVec.fit_transform(yahoo)\n",
      "# yahoo_results = clf_MNB.predict_proba(yahooXnew)\n",
      "# yahoo_nyt_results = yahoo_results[:,0]\n",
      "    \n",
      "nytXnew = newVec.fit_transform(NYT)\n",
      "nyt_results = clf_MNB.predict_proba(nytXnew)\n",
      "nyt_nyt_results = nyt_results[:,0]\n",
      "\n",
      "foxXnew = newVec.fit_transform(Fox)\n",
      "fox_results = clf_MNB.predict_proba(foxXnew)\n",
      "fox_nyt_results = fox_results[:,0]\n",
      "\n",
      "ABC_OzXnew = newVec.fit_transform(ABC_Oz)\n",
      "ABC_Oz_results = clf_MNB.predict_proba(ABC_OzXnew)\n",
      "ABC_Oz_nyt_results = ABC_Oz_results[:,0]\n",
      "\n",
      "OnionXnew = newVec.fit_transform(Onion)\n",
      "Onion_results = clf_MNB.predict_proba(OnionXnew)\n",
      "Onion_nyt_results = Onion_results[:,0]\n",
      "\n",
      "buzzfeedXnew = newVec.fit_transform(buzzfeed)\n",
      "buzzfeed_results = clf_MNB.predict_proba(buzzfeedXnew)\n",
      "buzzfeed_nyt_results = buzzfeed_results[:,0]\n",
      "\n",
      "BBCXnew = newVec.fit_transform(BBC)\n",
      "BBC_results = clf_MNB.predict_proba(BBCXnew)\n",
      "BBC_nyt_results = BBC_results[:,0]\n",
      "\n",
      "ABCXnew = newVec.fit_transform(ABC)\n",
      "ABC_results = clf_MNB.predict_proba(ABCXnew)\n",
      "ABC_nyt_results = ABC_results[:,0]\n",
      "\n",
      "CNNXnew = newVec.fit_transform(CNN)\n",
      "CNN_results = clf_MNB.predict_proba(CNNXnew)\n",
      "CNN_nyt_results = CNN_results[:,0]\n",
      "\n",
      "WJXnew = newVec.fit_transform(WJ)\n",
      "WJ_results = clf_MNB.predict_proba(WJXnew)\n",
      "WJ_nyt_results = WJ_results[:,0]\n",
      "\n",
      "LA_timesXnew = newVec.fit_transform(LA_times)\n",
      "LA_times_results = clf_MNB.predict_proba(LA_timesXnew)\n",
      "LA_times_nyt_results = LA_times_results[:,0]\n",
      "\n",
      "NBCXnew = newVec.fit_transform(NBC)\n",
      "NBC_results = clf_MNB.predict_proba(NBCXnew)\n",
      "NBC_nyt_results = NBC_results[:,0]\n",
      "\n",
      "Huff_postXnew = newVec.fit_transform(Huff_post)\n",
      "Huff_post_results = clf_MNB.predict_proba(Huff_postXnew)\n",
      "Huff_post_nyt_results = Huff_post_results[:,0]\n",
      "\n",
      "USA_todayXnew = newVec.fit_transform(USA_today)\n",
      "USA_today_results = clf_MNB.predict_proba(USA_todayXnew)\n",
      "USA_today_nyt_results = USA_today_results[:,0]\n",
      "\n",
      "\n",
      "print '   NYT         Buzz'\n",
      "# print np.round(yahoo_results,3)\n",
      "print 'NYT'\n",
      "print np.round(nyt_results,3)\n",
      "print 'Fox'\n",
      "print np.round(fox_results,3)\n",
      "print 'ABC OZ'\n",
      "print np.round(ABC_Oz_results,3)\n",
      "print 'Buzzfeed'\n",
      "print np.round(buzzfeed_results,3)\n",
      "print 'Onion'\n",
      "print np.round(Onion_results,3)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   NYT         Buzz\n",
        "NYT\n",
        "[[ 1.     0.   ]\n",
        " [ 0.704  0.296]\n",
        " [ 0.951  0.049]\n",
        " [ 0.998  0.002]\n",
        " [ 0.992  0.008]\n",
        " [ 0.981  0.019]\n",
        " [ 0.998  0.002]\n",
        " [ 0.868  0.132]\n",
        " [ 0.981  0.019]\n",
        " [ 0.995  0.005]]\n",
        "Fox\n",
        "[[ 0.879  0.121]\n",
        " [ 1.     0.   ]\n",
        " [ 0.998  0.002]\n",
        " [ 0.004  0.996]\n",
        " [ 0.08   0.92 ]\n",
        " [ 0.999  0.001]\n",
        " [ 0.989  0.011]\n",
        " [ 0.945  0.055]\n",
        " [ 0.87   0.13 ]\n",
        " [ 0.87   0.13 ]]\n",
        "ABC OZ\n",
        "[[ 0.999  0.001]\n",
        " [ 0.662  0.338]\n",
        " [ 0.113  0.887]\n",
        " [ 0.529  0.471]\n",
        " [ 0.758  0.242]\n",
        " [ 0.307  0.693]\n",
        " [ 0.731  0.269]\n",
        " [ 0.997  0.003]\n",
        " [ 0.998  0.002]\n",
        " [ 0.968  0.032]]\n",
        "Buzzfeed\n",
        "[[ 0.     1.   ]\n",
        " [ 0.047  0.953]\n",
        " [ 0.     1.   ]\n",
        " [ 0.     1.   ]\n",
        " [ 0.     1.   ]\n",
        " [ 0.001  0.999]\n",
        " [ 0.     1.   ]\n",
        " [ 0.     1.   ]\n",
        " [ 0.     1.   ]\n",
        " [ 0.002  0.998]]\n",
        "Onion\n",
        "[[ 0.526  0.474]\n",
        " [ 0.137  0.863]\n",
        " [ 1.     0.   ]\n",
        " [ 0.017  0.983]\n",
        " [ 0.001  0.999]\n",
        " [ 0.     1.   ]\n",
        " [ 0.     1.   ]\n",
        " [ 0.098  0.902]\n",
        " [ 0.326  0.674]\n",
        " [ 0.096  0.904]]\n"
       ]
      }
     ],
     "prompt_number": 276
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# #1 buzz, 0 NYT\n",
      "# clf_MNB = MultinomialNB(alpha=1).fit(X, Y)\n",
      "\n",
      "# newVec = CountVectorizer(vocabulary=vectorizer.vocabulary_)\n",
      "# yahoo = [\"obama visits new tax\"]\n",
      "# yahooXnew = newVec.fit_transform(yahoo)\n",
      "# yahoo_results = clf_MNB.predict_proba(yahooXnew)\n",
      "# yahoo_nyt_results = yahoo_results[:,0]\n",
      "# print np.round(yahoo_results,3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.992  0.008]]\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "  (861, 8161)\t1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# y_pred = clf_MNB.predict_proba(xtrain)\n",
      "# print y_pred\n",
      "# tags = list(set(xtest)\n",
      "# probs = y_pred.tolist() \n",
      "\n",
      "# print [zip(i, tags) for i in probs]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nyt_nyt_results.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(9,)\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print list(enumerate(vectorizer.get_feature_names()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pylab as plt\n",
      "font = {'size'   : 20}\n",
      "plt.rc('xtick', labelsize=20) \n",
      "plt.rc('ytick', labelsize=20)\n",
      "plt.rc('font', **font)\n",
      "\n",
      "fig= plt.figure()\n",
      "# fig.set_figheight(5)\n",
      "# fig.set_figwidth(5)\n",
      "# plt.hold = True\n",
      "boxes=[]\n",
      "ax = plt.gca()\n",
      "# boxes.append(yahoo_nyt_results)\n",
      "boxes.append(nyt_nyt_results)\n",
      "boxes.append(fox_nyt_results)\n",
      "boxes.append(buzzfeed_results)\n",
      "\n",
      "means = []\n",
      "means.append(np.mean(nyt_nyt_results))\n",
      "means.append(np.mean(fox_nyt_results))\n",
      "means.append(np.mean(ABC_Oz_nyt_results))\n",
      "means.append(np.mean(Onion_nyt_results))\n",
      "means.append(np.mean(BBC_nyt_results))\n",
      "means.append(np.mean(ABC_nyt_results))\n",
      "means.append(np.mean(CNN_nyt_results))\n",
      "means.append(np.mean(WJ_nyt_results))\n",
      "means.append(np.mean(LA_times_nyt_results))\n",
      "means.append(np.mean(NBC_nyt_results))\n",
      "means.append(np.mean(Huff_post_nyt_results))\n",
      "means.append(np.mean(USA_today_nyt_results))\n",
      "means.append(np.mean(buzzfeed_nyt_results))\n",
      "\n",
      "\n",
      "plt.tight_layout()\n",
      "ax.set_xticks([-0,0.95])\n",
      "ax.set_xlim([-0.025,1.025])\n",
      "\n",
      "plt.tick_params(\\\n",
      "    axis='x',          # changes apply to the x-axis\n",
      "    which='both',      # both major and minor ticks are affected\n",
      "    bottom='off',      # ticks along the bottom edge are off\n",
      "    top='off',         # ticks along the top edge are off\n",
      "    labelbottom='on')\n",
      "\n",
      "ax.set_xticklabels(('More like Buzz Feed', 'More like New York Times'))\n",
      "ax.set_yticks([0,14])\n",
      "\n",
      "labels = ['New York Times', 'Fox News', 'ABC Australia', 'The Onion', 'BBC', 'ABC',\n",
      "                    'CNN', 'Wall Street Jrnl.', 'LA Times', 'NBC', 'Huffington Post', 'USA Today','BuzzFeed']\n",
      "ys = range(1,len(means)+1)\n",
      "xs = means\n",
      "\n",
      "for i in range(len(labels)):\n",
      "    if i == 8:\n",
      "        plt.text(xs[i]-0.10, ys[i]-0.125, labels[i])\n",
      "    elif i == 0:\n",
      "        plt.text(xs[i]-0.163, ys[i]-0.125, labels[i])\n",
      "    else:\n",
      "        plt.text(xs[i]+0.015, ys[i]-0.125, labels[i])\n",
      "\n",
      "ax.annotate(\"\",\n",
      "            xy=(0, 0.5), xycoords='data',\n",
      "            xytext=(0.5, 0.5), textcoords='data',\n",
      "            size=30, va=\"center\", ha=\"center\",\n",
      "            arrowprops=dict(arrowstyle=\"simple\", facecolor ='blue', alpha=0.5), \n",
      "            )\n",
      "\n",
      "ax.annotate(\"\",\n",
      "            xy=(1., 0.5), xycoords='data',\n",
      "            xytext=(.5, 0.5), textcoords='data',\n",
      "            size=30, va=\"center\", ha=\"center\",\n",
      "            arrowprops=dict(arrowstyle=\"simple\", facecolor ='red', alpha = 0.5), \n",
      "            )\n",
      "# plt.boxplot(boxes,vert=0)\n",
      "plt.scatter(means, range(1,len(means)+1), marker = 'o', c =means, alpha=0.75, s=200)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 292
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print means"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.94661752725489379, 0.76342355855815902, 0.70618594042874272, 0.22010549232696475, 0.88109838243802407, 0.31978393067889088, 0.40885855453791076, 0.62296701931244136, 0.97034991016964367, 0.39055000712705007, 0.25889975136173915, 0.61167465153485101, 0.0049508397774727228]\n"
       ]
      }
     ],
     "prompt_number": 236
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}